# Crawler Connection Management

## T·ªïng quan

H·ªá th·ªëng WebSocket server ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p ƒë·ªÉ t·ª± ƒë·ªông qu·∫£n l√Ω tr·∫°ng th√°i online/offline c·ªßa c√°c crawler th√¥ng qua ping/pong mechanism.

## C√°ch ho·∫°t ƒë·ªông

### 1. K·∫øt n·ªëi v√† Welcome Event

Khi m·ªôt service crawler k·∫øt n·ªëi v·ªõi WebSocket server:

```
ws://localhost:3000/ws/crawler-events/<crawlerId>
```

Service s·∫Ω g·ª≠i welcome event:

```json
{
  "type": "welcome"
}
```

Server s·∫Ω:

- Ki·ªÉm tra crawler c√≥ t·ªìn t·∫°i trong database kh√¥ng
- N·∫øu c√≥: set `is_online = true` v√† g·ª≠i `welcome_ack`
- N·∫øu kh√¥ng: t·ª± ƒë·ªông t·∫°o crawler m·ªõi v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh, sau ƒë√≥ set `is_online = true` v√† g·ª≠i `welcome_ack`

### 2. Ping/Pong Mechanism

- **Individual Ping Intervals**: M·ªói crawler c√≥ ping interval ri√™ng bi·ªát (30 gi√¢y)
- **Individual Timeout**: M·ªói crawler c√≥ timeout check ri√™ng bi·ªát (60 gi√¢y = 1 ph√∫t)
- **Isolated Behavior**: M·ªôt crawler offline kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c crawler kh√°c
- **Simple Logic**: C√≥ pong = set online, kh√¥ng c√≥ pong trong 1 ph√∫t = set offline
- **Timeout Behavior**: Khi timeout, set offline v√† ng·ª´ng ping nh∆∞ng gi·ªØ connection
- **Welcome Restart**: Khi nh·∫≠n welcome event, restart ping cho crawler ƒë√≥
- **Pong Response**: Crawler ph·∫£i tr·∫£ l·ªùi v·ªõi `type: "pong"` ƒë·ªÉ reset timeout

### 3. T·ª± ƒë·ªông Cleanup

- Khi crawler disconnect: t·ª± ƒë·ªông set `is_online = false`
- Khi ping timeout: t·ª± ƒë·ªông set `is_online = false`
- Graceful shutdown: cleanup t·∫•t c·∫£ connections

## API Events

### Server ‚Üí Crawler

#### Ping

```json
{
  "type": "ping",
  "timestamp": "2024-01-01T00:00:00.000Z",
  "crawlerId": "crawler-123"
}
```

#### Welcome Acknowledgment

```json
{
  "type": "welcome_ack",
  "message": "Welcome acknowledged, crawler set online",
  "timestamp": "2024-01-01T00:00:00.000Z",
  "crawlerId": "crawler-123"
}
```

### Crawler ‚Üí Server

#### Welcome

```json
{
  "type": "welcome"
}
```

#### Pong

```json
{
  "type": "pong"
}
```

## Database Schema

Crawler table c√≥ field `is_online` ƒë·ªÉ track tr·∫°ng th√°i:

```sql
is_online BOOLEAN DEFAULT FALSE NOT NULL
```

## Monitoring

Server logs s·∫Ω hi·ªÉn th·ªã:

- `üéâ Received welcome from crawler <id>`
- `üÜï Crawler <id> not found, creating new crawler...` (n·∫øu crawler ch∆∞a t·ªìn t·∫°i)
- `‚úÖ Created default token <id>` (n·∫øu c·∫ßn t·∫°o default token)
- `‚úÖ Created new crawler <id> with default values` (n·∫øu t·∫°o crawler m·ªõi)
- `‚úÖ Crawler <id> connected and set online`
- `üîÑ Restarting ping for existing crawler <id>` (restart ping khi welcome)
- `üèì Ping sent to crawler <id>` (d·ª±a v√†o WebSocket connection)
- `üèì Pong received from crawler <id>` (reset timeout v√† set online)
- `‚úÖ Crawler <id> set online due to pong response` (set online khi c√≥ pong)
- `üíÄ Connection timeout for crawler <id>` (timeout ri√™ng bi·ªát)
- `üì¥ Crawler <id> set offline due to timeout (no pong)` (set offline khi kh√¥ng c√≥ pong)
- `‚è∏Ô∏è Ping stopped for crawler <id>, waiting for welcome event` (ng·ª´ng ping, gi·ªØ connection)

## C·∫•u h√¨nh

C√°c th√¥ng s·ªë c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh th√¥ng qua environment variables:

```bash
# WebSocket Configuration
PING_INTERVAL=30000    # Ping interval in milliseconds (default: 30000ms = 30s)
PING_TIMEOUT=10000     # Ping timeout in milliseconds (default: 10000ms = 10s)
WEBSOCKET_URL=ws://localhost:3000
```

### Environment Variables

| Variable        | Default               | Description                                         |
| --------------- | --------------------- | --------------------------------------------------- |
| `PING_INTERVAL` | `30000`               | Interval between ping messages (milliseconds)       |
| `PING_TIMEOUT`  | `60000`               | Timeout for ping response (milliseconds) - 1 minute |
| `WEBSOCKET_URL` | `ws://localhost:3000` | WebSocket server URL                                |

### V√≠ d·ª• c·∫•u h√¨nh

```bash
# .env file
PING_INTERVAL=60000    # Ping m·ªói 60 gi√¢y
PING_TIMEOUT=15000     # Timeout sau 15 gi√¢y
```

Ho·∫∑c khi ch·∫°y:

```bash
PING_INTERVAL=45000 PING_TIMEOUT=12000 npm start
```

## Auto-Creation Feature

### T·ª± ƒë·ªông t·∫°o Crawler

Khi m·ªôt crawler v·ªõi ID ch∆∞a t·ªìn t·∫°i k·∫øt n·ªëi v√† g·ª≠i welcome event, h·ªá th·ªëng s·∫Ω:

1. **T·∫°o Default Token** (n·∫øu ch∆∞a c√≥):

   ```json
   {
     "id": "default-token",
     "name": "Default Token",
     "address": "0x0000000000000000000000000000000000000000",
     "chain": "ethereum",
     "digit": 18,
     "blockDeploy": "0"
   }
   ```

2. **T·∫°o Crawler m·ªõi** v·ªõi th√¥ng tin m·∫∑c ƒë·ªãnh:

   ```json
   {
     "id": "<crawlerId>",
     "name": "Crawler <crawlerId>",
     "token": "UNKNOWN",
     "address": "0x0000000000000000000000000000000000000000",
     "isOnline": false,
     "tokenId": "default-token"
   }
   ```

3. **Set crawler online** v√† thi·∫øt l·∫≠p ping/pong mechanism

### C·∫≠p nh·∫≠t th√¥ng tin Crawler

Sau khi crawler ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông, b·∫°n c√≥ th·ªÉ c·∫≠p nh·∫≠t th√¥ng tin th√¥ng qua API:

```typescript
import * as crawlerService from './services/crawlerService'

// C·∫≠p nh·∫≠t th√¥ng tin crawler
await crawlerService.updateCrawler('crawler-123', {
  name: 'Bitcoin Crawler',
  token: 'BTC',
  address: '0x1234567890abcdef',
  tokenId: 'bitcoin-token'
})
```

## S·ª≠ d·ª•ng

### Ki·ªÉm tra tr·∫°ng th√°i crawler

```typescript
import { crawlerConnectionManager } from './ws'

// L·∫•y th√¥ng tin connection
const connection = crawlerConnectionManager.getConnectionInfo('crawler-123')

// L·∫•y s·ªë l∆∞·ª£ng crawler ƒëang k·∫øt n·ªëi
const count = crawlerConnectionManager.getConnectedCount()

// L·∫•y t·∫•t c·∫£ connections
const allConnections = crawlerConnectionManager.getAllConnections()
```

### Service Functions

```typescript
import * as crawlerService from './services/crawlerService'

// L·∫•y crawler online
const onlineCrawlers = await crawlerService.getOnlineCrawlers()

// L·∫•y crawler offline
const offlineCrawlers = await crawlerService.getOfflineCrawlers()

// Set crawler online/offline manually
await crawlerService.setCrawlerOnline('crawler-123')
await crawlerService.setCrawlerOffline('crawler-123')
```
